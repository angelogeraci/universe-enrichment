'use client'
import React, { useEffect, useState, ChangeEvent, FormEvent } from 'react'
import { Input } from './ui/input'
import { Textarea } from './ui/textarea'
import { Button } from './ui/button'
import { useToast } from '@/hooks/useToast'
import { OPENAI_MODELS, getModelsByCategory, type OpenAIModel } from '@/lib/openai-models'
import { ANTHROPIC_MODELS, getAnthropicModelsByCategory, type AnthropicModel } from '@/lib/anthropic-models'

type Prompt = {
  id: string
  label: string
  template: string
  description?: string
  searchType?: string
  model?: string
  isActive: boolean
}

const OUTPUT_FORMAT_INSTRUCTION = `IMPORTANT - FORMAT DE R√âPONSE REQUIS:
Vous devez r√©pondre uniquement avec un tableau JSON de cha√Ænes de caract√®res, sans texte explicatif, sans balises markdown, sans formatage suppl√©mentaire.
Format attendu : ["item1", "item2", "item3"]
R√®gles strictes :
- R√©ponse UNIQUEMENT en format JSON array
- Chaque √©l√©ment est une cha√Æne de caract√®res
- Pas de texte avant ou apr√®s le JSON
- Pas de balises \`\`\`json ou autres
- Maximum 200 √©l√©ments par r√©ponse`

export default function PromptAdminEditor () {
  const [prompts, setPrompts] = useState<Prompt[]>([])
  const [loading, setLoading] = useState(true)
  const [saving, setSaving] = useState<string | null>(null)
  const { success, error: showError, info } = useToast()

  // Organise TOUS les mod√®les (OpenAI + Anthropic) par cat√©gories
  const allModelsByCategory = {
    // Mod√®les Anthropic Claude
    'Claude-4': getAnthropicModelsByCategory('Claude-4'),
    'Claude-3.5': getAnthropicModelsByCategory('Claude-3.5'),
    'Claude-3': getAnthropicModelsByCategory('Claude-3'),
    'Claude-Reasoning': getAnthropicModelsByCategory('Reasoning'),
    
    // Mod√®les OpenAI
    'GPT-4': getModelsByCategory('GPT-4'),
    'OpenAI-Reasoning': getModelsByCategory('Reasoning'),
    'GPT-3.5': getModelsByCategory('GPT-3.5'),
    
    // Garde compatibilit√© avec anciens mod√®les
    'legacy': OPENAI_MODELS.filter(m => m.category === 'legacy'),
    'standard': OPENAI_MODELS.filter(m => m.category === 'standard')
  }

  useEffect(() => {
    fetchPrompts()
  }, [])

  const fetchPrompts = async () => {
    try {
      const res = await fetch('/api/prompts')
      if (!res.ok) {
        throw new Error('Erreur lors du chargement des prompts')
      }
      const data = await res.json()
      if (data.prompts) {
        setPrompts(data.prompts.filter((p: Prompt) => p.isActive && p.searchType))
        info('Prompts charg√©s avec succ√®s', { duration: 2000 })
      }
      setLoading(false)
    } catch (error: any) {
      showError(error.message || 'Erreur lors du chargement des prompts', { duration: 5000 })
      setLoading(false)
    }
  }

  const handleChange = (promptId: string, field: string, value: string) => {
    setPrompts(prevPrompts => 
      prevPrompts.map(prompt => 
        prompt.id === promptId 
          ? { ...prompt, [field]: value }
          : prompt
      )
    )
  }

  const handleModelChange = (promptId: string, event: ChangeEvent<HTMLSelectElement>) => {
    handleChange(promptId, 'model', event.target.value)
  }

  const handleSave = async (prompt: Prompt) => {
    setSaving(prompt.id)
    
    try {
      const res = await fetch(`/api/prompts/${prompt.id}`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          label: prompt.label,
          template: prompt.template,
          description: prompt.description,
          searchType: prompt.searchType,
          model: prompt.model,
          isActive: true
        })
      })
      
      if (!res.ok) {
        const errorData = await res.json()
        throw new Error(errorData.error || 'Erreur lors de la sauvegarde')
      }
      
      success(`Prompt "${prompt.label}" sauvegard√© avec succ√®s !`, { duration: 4000 })
    } catch (e: any) {
      showError(e.message || 'Erreur lors de la sauvegarde du prompt', { duration: 5000 })
    } finally {
      setSaving(null)
    }
  }

  const getSearchTypeLabel = (searchType: string) => {
    switch (searchType) {
      case 'origin': return 'üè† Originaires uniquement'
      case 'presence': return 'üåç Originaires + Pr√©sents'
      default: return searchType
    }
  }

  const getSearchTypeDescription = (searchType: string) => {
    switch (searchType) {
      case 'origin': 
        return 'Ce prompt g√©n√®re uniquement des crit√®res qui sont strictement originaires du pays s√©lectionn√©.'
      case 'presence': 
        return 'Ce prompt g√©n√®re des crit√®res qui sont soit originaires du pays, soit populaires/pr√©sents dans ce pays.'
      default: 
        return 'Type de recherche non d√©fini'
    }
  }

  const getModelDescription = (modelId: string) => {
    // Chercher dans les mod√®les OpenAI d'abord
    const openaiModel = OPENAI_MODELS.find(m => m.id === modelId)
    if (openaiModel) return openaiModel.description
    
    // Chercher dans les mod√®les Anthropic
    const anthropicModel = ANTHROPIC_MODELS.find(m => m.id === modelId)
    if (anthropicModel) return anthropicModel.description
    
    return 'Mod√®le inconnu'
  }

  const isAnthropicModel = (modelId: string): boolean => {
    return ANTHROPIC_MODELS.some(m => m.id === modelId)
  }

  if (loading) return <div>Chargement des prompts...</div>
  if (prompts.length === 0) return <div>Aucun prompt configur√©.</div>

  return (
    <div className="space-y-8 max-w-4xl">
      <h2 className="text-2xl font-bold mb-4">üéØ Configuration des Prompts Sp√©cialis√©s</h2>
      
      {prompts.map((prompt) => (
        <div key={prompt.id} className="border rounded-lg p-6 bg-white shadow-sm">
          {/* Header avec type de recherche */}
          <div className="mb-4 p-4 bg-blue-50 rounded-lg border-l-4 border-blue-400">
            <h3 className="font-semibold text-lg text-blue-800 mb-2">
              {getSearchTypeLabel(prompt.searchType || '')}
            </h3>
            <p className="text-blue-700 text-sm">
              {getSearchTypeDescription(prompt.searchType || '')}
            </p>
          </div>

          <div className="space-y-4">
            <div>
              <label className="block font-medium mb-1">Label</label>
              <Input 
                value={prompt.label} 
                onChange={(e) => handleChange(prompt.id, 'label', e.target.value)}
                required 
              />
            </div>

            <div>
              <label className="block font-medium mb-1">Mod√®le IA</label>
              <select 
                value={prompt.model || 'gpt-4o'} 
                onChange={(e) => handleModelChange(prompt.id, e)}
                className="w-full p-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500 focus:border-transparent"
              >
                {/* Mod√®les Anthropic Claude */}
                <optgroup label="üîÆ Claude 4 (2025) - Anthropic">
                  {allModelsByCategory['Claude-4'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name} {model.id === 'claude-4-sonnet-20250522' ? '‚≠ê Dernier' : ''}
                    </option>
                  ))}
                </optgroup>

                <optgroup label="üß† Claude 3.5 (2024-2025) - Anthropic">
                  {allModelsByCategory['Claude-3.5'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name} {model.id === 'claude-3-5-sonnet-20241022' ? '‚≠ê Recommand√©' : ''}
                    </option>
                  ))}
                </optgroup>

                <optgroup label="üí≠ Claude Raisonnement - Anthropic">
                  {allModelsByCategory['Claude-Reasoning'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name} (Thinking)
                    </option>
                  ))}
                </optgroup>

                <optgroup label="üìö Claude 3 Classic - Anthropic">
                  {allModelsByCategory['Claude-3'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name}
                    </option>
                  ))}
                </optgroup>
                
                {/* S√©parateur visuel */}
                <optgroup label="‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ">
                  <option disabled>Mod√®les OpenAI</option>
                </optgroup>
                
                {/* Mod√®les OpenAI */}
                <optgroup label="üöÄ GPT-4 (2025) - OpenAI">
                  {allModelsByCategory['GPT-4'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name} {model.id === 'gpt-4o' ? '‚≠ê Recommand√©' : ''}
                    </option>
                  ))}
                </optgroup>
                
                <optgroup label="üß† OpenAI Raisonnement">
                  {allModelsByCategory['OpenAI-Reasoning'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name}
                    </option>
                  ))}
                </optgroup>
                
                <optgroup label="‚ö° GPT-3.5 - OpenAI">
                  {allModelsByCategory['GPT-3.5'].map((model) => (
                    <option key={model.id} value={model.id}>
                      {model.name}
                    </option>
                  ))}
                </optgroup>
                
                {allModelsByCategory['standard'] && allModelsByCategory['standard'].length > 0 && (
                  <optgroup label="üîß Standards">
                    {allModelsByCategory['standard'].map((model) => (
                      <option key={model.id} value={model.id}>
                        {model.name}
                      </option>
                    ))}
                  </optgroup>
                )}
                
                {allModelsByCategory['legacy'] && allModelsByCategory['legacy'].length > 0 && (
                  <optgroup label="üìú Classiques">
                    {allModelsByCategory['legacy'].map((model) => (
                      <option key={model.id} value={model.id}>
                        {model.name}
                      </option>
                    ))}
                  </optgroup>
                )}
              </select>
              <div className="text-xs text-gray-600 mt-1">
                <strong>S√©lectionn√©:</strong> {getModelDescription(prompt.model || 'gpt-4o')}
                {isAnthropicModel(prompt.model || 'gpt-4o') && 
                  <span className="ml-2 px-2 py-1 bg-purple-100 text-purple-800 rounded text-xs">
                    üîÆ Anthropic Claude
                  </span>
                }
                {!isAnthropicModel(prompt.model || 'gpt-4o') && 
                  <span className="ml-2 px-2 py-1 bg-green-100 text-green-800 rounded text-xs">
                    ü§ñ OpenAI
                  </span>
                }
              </div>
            </div>
            
            <div>
              <label className="block font-medium mb-1">Template du Prompt</label>
              <Textarea 
                value={prompt.template} 
                onChange={(e) => handleChange(prompt.id, 'template', e.target.value)}
                rows={12} 
                required 
                className="font-mono text-sm"
                placeholder="Utilisez {{category}}, {{categoryPath}} et {{country}} comme variables"
              />
              <p className="text-sm text-gray-600 mt-1">
                Variables disponibles: <code>{'{{category}}'}</code>, <code>{'{{categoryPath}}'}</code>, <code>{'{{country}}'}</code>
              </p>
            </div>

            <div>
              <label className="block font-medium mb-1">Description</label>
              <Textarea 
                value={prompt.description || ''} 
                onChange={(e) => handleChange(prompt.id, 'description', e.target.value)}
                rows={2} 
              />
            </div>

            <Button 
              onClick={() => handleSave(prompt)}
              disabled={saving === prompt.id}
              className="w-full"
            >
              {saving === prompt.id ? 'Sauvegarde...' : `Enregistrer ${getSearchTypeLabel(prompt.searchType || '')}`}
            </Button>
          </div>
        </div>
      ))}

      {/* Zone Format de Sortie - Non √âditable */}
      <div className="border-t pt-6">
        <div className="bg-gray-50 p-4 rounded-lg">
          <h3 className="font-semibold text-lg mb-3 text-gray-800">
            üìã Format de Sortie IA (Non Modifiable)
          </h3>
          <p className="text-sm text-gray-600 mb-3">
            Cette instruction est automatiquement ajout√©e √† vos prompts pour assurer la coh√©rence du format de r√©ponse avec <strong>tous les mod√®les</strong> (OpenAI et Anthropic):
          </p>
          <Textarea 
            value={OUTPUT_FORMAT_INSTRUCTION}
            readOnly 
            rows={12}
            className="bg-white border-gray-300 cursor-not-allowed font-mono text-sm"
          />
          <div className="mt-3 p-2 bg-blue-50 rounded border-l-4 border-blue-400">
            <p className="text-sm text-blue-800">
              <strong>‚ÑπÔ∏è Information:</strong> Cette partie est automatiquement combin√©e avec vos templates 
              lors de l'envoi aux mod√®les IA (OpenAI GPT et Anthropic Claude) pour garantir un format de r√©ponse coh√©rent.
            </p>
          </div>
        </div>
      </div>
    </div>
  )
} 